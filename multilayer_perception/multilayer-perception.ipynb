{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron: Fit and evaluate a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A multilayer perception is a classic feed forward artificial neural netowrk,the core component of deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "             n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "             random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "             validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "              validation_fraction=0.1, verbose=False, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "\n",
    "print(MLPRegressor())\n",
    "print(MLPClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning) \n",
    "warnings.filterwarnings('ignore', category=ConvergenceWarning)\n",
    "\n",
    "tr_features = pd.read_csv('../resources/train_features.csv')\n",
    "tr_labels = pd.read_csv('../resources/train_labels.csv', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(results):\n",
    "    print('BEST PARAMS: {}\\n'.format(results.best_params_))\n",
    "    means=results.cv_results_['mean_test_score']\n",
    "    stds=results.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, results.cv_results_['params']):\n",
    "        print('{} (+/-{}) for {}'.format(round(mean, 3), round(std * 2, 3), params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS: {'activation': 'tanh', 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive'}\n",
      "\n",
      "0.723 (+/-0.114) for {'activation': 'relu', 'hidden_layer_sizes': (10,), 'learning_rate': 'constant'}\n",
      "0.764 (+/-0.054) for {'activation': 'relu', 'hidden_layer_sizes': (10,), 'learning_rate': 'invscaling'}\n",
      "0.691 (+/-0.086) for {'activation': 'relu', 'hidden_layer_sizes': (10,), 'learning_rate': 'adaptive'}\n",
      "0.792 (+/-0.113) for {'activation': 'relu', 'hidden_layer_sizes': (50,), 'learning_rate': 'constant'}\n",
      "0.772 (+/-0.155) for {'activation': 'relu', 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling'}\n",
      "0.79 (+/-0.114) for {'activation': 'relu', 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive'}\n",
      "0.8 (+/-0.11) for {'activation': 'relu', 'hidden_layer_sizes': (100,), 'learning_rate': 'constant'}\n",
      "0.794 (+/-0.082) for {'activation': 'relu', 'hidden_layer_sizes': (100,), 'learning_rate': 'invscaling'}\n",
      "0.785 (+/-0.164) for {'activation': 'relu', 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive'}\n",
      "0.721 (+/-0.131) for {'activation': 'tanh', 'hidden_layer_sizes': (10,), 'learning_rate': 'constant'}\n",
      "0.706 (+/-0.08) for {'activation': 'tanh', 'hidden_layer_sizes': (10,), 'learning_rate': 'invscaling'}\n",
      "0.691 (+/-0.162) for {'activation': 'tanh', 'hidden_layer_sizes': (10,), 'learning_rate': 'adaptive'}\n",
      "0.779 (+/-0.13) for {'activation': 'tanh', 'hidden_layer_sizes': (50,), 'learning_rate': 'constant'}\n",
      "0.785 (+/-0.112) for {'activation': 'tanh', 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling'}\n",
      "0.781 (+/-0.149) for {'activation': 'tanh', 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive'}\n",
      "0.788 (+/-0.105) for {'activation': 'tanh', 'hidden_layer_sizes': (100,), 'learning_rate': 'constant'}\n",
      "0.798 (+/-0.074) for {'activation': 'tanh', 'hidden_layer_sizes': (100,), 'learning_rate': 'invscaling'}\n",
      "0.809 (+/-0.11) for {'activation': 'tanh', 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive'}\n",
      "0.697 (+/-0.115) for {'activation': 'logistic', 'hidden_layer_sizes': (10,), 'learning_rate': 'constant'}\n",
      "0.691 (+/-0.094) for {'activation': 'logistic', 'hidden_layer_sizes': (10,), 'learning_rate': 'invscaling'}\n",
      "0.706 (+/-0.081) for {'activation': 'logistic', 'hidden_layer_sizes': (10,), 'learning_rate': 'adaptive'}\n",
      "0.768 (+/-0.118) for {'activation': 'logistic', 'hidden_layer_sizes': (50,), 'learning_rate': 'constant'}\n",
      "0.779 (+/-0.121) for {'activation': 'logistic', 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling'}\n",
      "0.747 (+/-0.106) for {'activation': 'logistic', 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive'}\n",
      "0.777 (+/-0.146) for {'activation': 'logistic', 'hidden_layer_sizes': (100,), 'learning_rate': 'constant'}\n",
      "0.785 (+/-0.127) for {'activation': 'logistic', 'hidden_layer_sizes': (100,), 'learning_rate': 'invscaling'}\n",
      "0.783 (+/-0.111) for {'activation': 'logistic', 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive'}\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier()\n",
    "parameters = {\n",
    "    'hidden_layer_sizes': [(10,), (50,), (100,)],#the number of neurons in the ith hidden layer.\n",
    "    'activation': ['relu', 'tanh', 'logistic'],#Activation function for the hidden layer.\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'], #constant’ is a constant learning rate given by ‘learning_rate_init’.\n",
    "                                        #‘invscaling’ gradually decreases the learning rate at each time step ‘t’ \n",
    "                                                          \n",
    "}\n",
    "\n",
    "cv = GridSearchCV(mlp, parameters, cv=5)\n",
    "cv.fit(tr_features, tr_labels.values.ravel())\n",
    "\n",
    "print_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(100,), learning_rate='adaptive',\n",
       "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write out pickled model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../resources/MLP_model.pkl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(cv.best_estimator_, '../resources/MLP_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
